<div align="center">

![](https://github.com/user-attachments/assets/865632a4-911f-4de4-867d-c65cef365d79)

# ğŸš€ Easy Dataset CLI

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.9+-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/CLI-Typer-green.svg" alt="CLI Framework">
  <img src="https://img.shields.io/badge/LLM-OpenAI%20%7C%20OpenRouter-orange.svg" alt="LLM Support">
  <img src="https://img.shields.io/badge/Format-Alpaca%20%7C%20XML-purple.svg" alt="Output Format">
  <img src="https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow.svg" alt="Hugging Face">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
</p>

<p align="center">
  ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Q&Aãƒšã‚¢ã‚’ç”Ÿæˆã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ãªCLIãƒ„ãƒ¼ãƒ«<br>
  LLMã‚’ä½¿ç”¨ã—ã¦Genre-Audienceãƒšã‚¢ã«åŸºã¥ã„ãŸå¤šæ§˜ãªQ&Aãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã€<br>
  <strong>Alpacaå½¢å¼JSON</strong>ã‚„Genreåˆ¥XMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦å‡ºåŠ›ã€<strong>Hugging Face Hub</strong>ã¸ã®ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚‚å¯¾å¿œ
</p>

</div>

## âœ¨ ç‰¹å¾´

- **ğŸ¯ ã‚·ãƒ³ãƒ—ãƒ«**: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¸è¦ã€ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§GAå®šç¾©
- **ğŸ”„ æŸ”è»Ÿ**: è¤‡æ•°ã®Genre-Audienceãƒšã‚¢ã«å¯¾å¿œ
- **ğŸ›¡ï¸ å®‰å®š**: LLMã‹ã‚‰ã®ç›´æ¥XMLå‡ºåŠ›ã§ä¿¡é ¼æ€§å‘ä¸Š
- **âš¡ åŠ¹ç‡çš„**: ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ã¨ãƒãƒƒãƒå‡¦ç†ã§å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚‚å¯¾å¿œ
- **ğŸ¦™ Alpacaå¯¾å¿œ**: ç”Ÿæˆã•ã‚ŒãŸQ&Aãƒšã‚¢ã‚’Alpacaå½¢å¼ã®JSONã§å‡ºåŠ›
- **ğŸ¤— HFçµ±åˆ**: Hugging Face Hubã¸ã®ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
- **ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰**: è‡ªå‹•çš„ãªREADME.mdç”Ÿæˆã§ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã‚’æ•´ç†
- **ğŸ”„ å¤‰æ›æ©Ÿèƒ½**: æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Alpacaå½¢å¼ã¸ã®å¤‰æ›ã‚³ãƒãƒ³ãƒ‰

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ã¾ãŸã¯
venv\Scripts\activate     # Windows

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -e .
```

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### ğŸ“‹ åŸºæœ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

1. **GAãƒšã‚¢å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã®è‡ªå‹•ç”Ÿæˆ**
```bash
# ç’°å¢ƒå¤‰æ•°ã«APIã‚­ãƒ¼ã‚’è¨­å®š
export OPENAI_API_KEY="your-api-key-here"

# å…ƒã®æ–‡ç« ã‹ã‚‰GAãƒšã‚¢å®šç¾©ã‚’è‡ªå‹•ç”Ÿæˆ
uv run easy-dataset create-ga .\example\input\documents\sample_document.txt --output-dir .\example\output\sample_document --num-ga-pairs 10
```

2. **Q&Aãƒšã‚¢ã®ç”Ÿæˆ**
```bash
# GAãƒšã‚¢å®šç¾©ã‚’ä½¿ã£ã¦Q&Aãƒšã‚¢ã‚’ç”Ÿæˆ
uv run easy-dataset generate .\example\input\documents\sample_document.txt --ga-file .\example\output\sample_document\ga\ga_definitions.xml --output-dir .\example\output\sample_document\ --chunk-size 500
```

### ğŸ¦™ Alpacaå½¢å¼ã¨Hugging Faceé€£æºã®ä½¿ç”¨ä¾‹

#### Alpacaå½¢å¼ã§ã®å‡ºåŠ›
```bash
# Q&Aç”Ÿæˆã¨åŒæ™‚ã«Alpacaå½¢å¼ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡ºåŠ›
uv run easy-dataset generate .\example\input\documents\sample_document.txt \
  --ga-file .\example\output\sample_document\ga\ga_definitions.xml \
  --output-dir .\example\output\sample_document\ \
  --export-alpaca
```

#### Hugging Face Hubã¸ã®ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```bash
# ç’°å¢ƒå¤‰æ•°ã§ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è¨­å®š
set HUGGINGFACE_TOKEN=hf_your_token_here

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆç”Ÿæˆã¨Hugging Face Hubã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ä¸€åº¦ã«å®Ÿè¡Œ
uv run easy-dataset generate .\example\input\documents\sample_document.txt \
  --ga-file .\example\output\sample_document\ga\ga_definitions.xml \
  --output-dir .\example\output\sample_document\ \
  --export-alpaca \
  --upload-hf \
  --hf-repo-name username/my-qa-dataset
```

#### æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ›ã¨ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```bash
# æ—¢å­˜ã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’Alpacaå½¢å¼ã«å¤‰æ›ã—ã¦Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uv run easy-dataset convert-to-alpaca .\example\output\sample_document\qa \
  --output-file dataset.json \
  --upload-hf \
  --hf-repo-name username/my-qa-dataset \
  --hf-private
```

### âš™ï¸ ã‚³ãƒãƒ³ãƒ‰ã‚ªãƒ—ã‚·ãƒ§ãƒ³

#### ğŸ”§ create-ga ã‚³ãƒãƒ³ãƒ‰
```bash
uv run easy-dataset create-ga [OPTIONS] FILE_PATH

Arguments:
  FILE_PATH  GAãƒšã‚¢ã®å®šç¾©ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ« [required]

Options:
  -o, --output-dir DIRECTORY  ç”Ÿæˆã•ã‚ŒãŸGAãƒšã‚¢å®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª [required]
  -m, --model TEXT           GAãƒšã‚¢å®šç¾©ã®ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«å [default: openrouter/openai/gpt-4o]
  -g, --num-ga-pairs INTEGER ç”Ÿæˆã™ã‚‹GAãƒšã‚¢ã®æ•°ã€‚æŒ‡å®šã—ãªã„å ´åˆã¯LLMãŒé©åˆ‡ãªæ•°ã‚’æ±ºå®šã—ã¾ã™
  -h, --help                 Show this message and exit
```

#### ğŸ”§ generate ã‚³ãƒãƒ³ãƒ‰
```bash
uv run easy-dataset generate [OPTIONS] FILE_PATH

Arguments:
  FILE_PATH  å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ [required]

Options:
  --ga-file PATH           Genre-Audienceãƒšã‚¢ã‚’å®šç¾©ã—ãŸXMLãƒ•ã‚¡ã‚¤ãƒ« [required]
  -o, --output-dir PATH    XMLãƒ•ã‚¡ã‚¤ãƒ«ã®å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
  -m, --model TEXT         Q&Aãƒšã‚¢ã®ç”Ÿæˆã«ä½¿ç”¨ã™ã‚‹LLMãƒ¢ãƒ‡ãƒ« [default: openrouter/openai/gpt-4o]
  --chunk-size INTEGER     ãƒ†ã‚­ã‚¹ãƒˆãƒãƒ£ãƒ³ã‚¯ã®æœ€å¤§ã‚µã‚¤ã‚º [default: 2000]
  --chunk-overlap INTEGER  ãƒãƒ£ãƒ³ã‚¯é–“ã®ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—ã‚µã‚¤ã‚º [default: 200]
  -h, --help               Show this message and exit
```

## ğŸ“„ GAå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼

`create-ga`ã‚³ãƒãƒ³ãƒ‰ã§è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹GAå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã¯XMLå½¢å¼ã§ä¿å­˜ã•ã‚Œã¾ã™ï¼š

```xml
<?xml version="1.0" encoding="utf-8"?>
<GADefinitions>
  <Pair>
    <Genre>å­¦è¡“è«–æ–‡</Genre>
    <GenreDescription>å­¦è¡“çš„ã§å³å¯†ãªè¡¨ç¾ã‚’ç”¨ã„ã€å°‚é–€ç”¨èªã‚’æ­£ç¢ºã«ä½¿ç”¨ã—ã€è«–ç†çš„ã§å®¢è¦³çš„ãªå›ç­”ã‚’æä¾›ã—ã¾ã™ã€‚</GenreDescription>
    <Audience>ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç ”ç©¶è€…</Audience>
    <AudienceDescription>ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹åˆ†é‡ã®ç ”ç©¶è€…å‘ã‘ã«ã€æœ€æ–°ã®ç ”ç©¶å‹•å‘ã‚„ç†è«–çš„èƒŒæ™¯ã‚’å«ã‚€å°‚é–€çš„ãªå†…å®¹ã‚’æä¾›ã—ã¾ã™ã€‚</AudienceDescription>
  </Pair>
  <Pair>
    <Genre>æŠ€è¡“ãƒ–ãƒ­ã‚°</Genre>
    <GenreDescription>å®Ÿè·µçš„ã§è¦ªã—ã¿ã‚„ã™ã„è¡¨ç¾ã‚’ç”¨ã„ã€å…·ä½“ä¾‹ã‚„ã‚³ãƒ¼ãƒ‰ä¾‹ã‚’äº¤ãˆã¦èª¬æ˜ã—ã¾ã™ã€‚</GenreDescription>
    <Audience>ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°åˆå¿ƒè€…</Audience>
    <AudienceDescription>ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚’å­¦ã³å§‹ã‚ãŸåˆå¿ƒè€…å‘ã‘ã«ã€åŸºç¤çš„ãªæ¦‚å¿µã‚’åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¾ã™ã€‚</AudienceDescription>
  </Pair>
</GADefinitions>
```

ã¾ãŸã€å„Genreåˆ¥ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ç”Ÿæˆã•ã‚Œã€å¿…è¦ã«å¿œã˜ã¦æ‰‹å‹•ã§ç·¨é›†ã§ãã¾ã™ã€‚

## ğŸ“ å‡ºåŠ›å½¢å¼

### ğŸ“„ XMLå½¢å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

`generate`ã‚³ãƒãƒ³ãƒ‰ã®å®Ÿè¡Œã«ã‚ˆã‚Šã€å„Genreã”ã¨ã«XMLãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼š

```xml
<?xml version="1.0" ?>
<QAPairs genre="å­¦è¡“è«–æ–‡">
  <Pair>
    <Audience>ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç ”ç©¶è€…</Audience>
    <Question>Pythonã®è¨­è¨ˆå“²å­¦ã«ãŠã‘ã‚‹ä¸»è¦ãªç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ</Question>
    <Answer>Pythonã®è¨­è¨ˆå“²å­¦ã¯ã€Œèª­ã¿ã‚„ã™ã•ã€ã‚’é‡è¦–ã—ã¦ãŠã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ã§ç†è§£ã—ã‚„ã™ã„æ§‹æ–‡ãŒç‰¹å¾´ã§ã™ã€‚</Answer>
  </Pair>
</QAPairs>
```

### ğŸ¦™ Alpacaå½¢å¼ï¼ˆ`--export-alpaca`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

`--export-alpaca`ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã™ã‚‹ã¨ã€æ©Ÿæ¢°å­¦ç¿’ã§åºƒãä½¿ç”¨ã•ã‚Œã‚‹Alpacaå½¢å¼ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã™ï¼š

```json
[
  {
    "instruction": "Pythonã®è¨­è¨ˆå“²å­¦ã«ãŠã‘ã‚‹ä¸»è¦ãªç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "input": "",
    "output": "Pythonã®è¨­è¨ˆå“²å­¦ã¯ã€Œèª­ã¿ã‚„ã™ã•ã€ã‚’é‡è¦–ã—ã¦ãŠã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ã§ç†è§£ã—ã‚„ã™ã„æ§‹æ–‡ãŒç‰¹å¾´ã§ã™ã€‚",
    "genre": "å­¦è¡“è«–æ–‡",
    "audience": "ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç ”ç©¶è€…"
  },
  {
    "instruction": "Pythonã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼å‹è¨€èªã¨ã—ã¦ã®åˆ©ç‚¹ã¯ä½•ã§ã™ã‹ï¼Ÿ",
    "input": "",
    "output": "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ—ãƒªã‚¿ãƒ¼å‹ã®ãŸã‚ã€ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ä¸è¦ã§å³åº§ã«ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ãã€é–‹ç™ºã‚µã‚¤ã‚¯ãƒ«ãŒé«˜é€ŸåŒ–ã•ã‚Œã¾ã™ã€‚",
    "genre": "æŠ€è¡“ãƒ–ãƒ­ã‚°",
    "audience": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°åˆå¿ƒè€…"
  }
]
```

### ğŸ“Š è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰

Alpacaå½¢å¼ã§å‡ºåŠ›ã™ã‚‹éš›ã€ä»¥ä¸‹ã®æƒ…å ±ã‚’å«ã‚€README.mdãŒè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™ï¼š

- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦**: ã‚¨ãƒ³ãƒˆãƒªæ•°ã€å½¢å¼ã€è¨€èªã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
- **ã‚¸ãƒ£ãƒ³ãƒ«åˆ†å¸ƒ**: å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ã‚¸ãƒ£ãƒ³ãƒ«ã®ãƒªã‚¹ãƒˆ
- **å¯¾è±¡èª­è€…åˆ†å¸ƒ**: å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®å¯¾è±¡èª­è€…ã®ãƒªã‚¹ãƒˆ
- **ä½¿ç”¨æ–¹æ³•**: Hugging Face Datasetsã§ã®èª­ã¿è¾¼ã¿ä¾‹
- **ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿**: Hugging Face Hubç”¨ã®YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼

### ğŸ“ ç”Ÿæˆã•ã‚Œã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ 

```
output_directory/
â”œâ”€â”€ ga/
â”‚   â”œâ”€â”€ ga_definitions.xml          # ãƒ¡ã‚¤ãƒ³ã®GAå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ ga_definitions_å­¦è¡“è«–æ–‡.md   # Genreåˆ¥ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«
â”‚   â”œâ”€â”€ ga_definitions_æŠ€è¡“ãƒ–ãƒ­ã‚°.md
â”‚   â””â”€â”€ ...
â”œâ”€â”€ qa/
â”‚   â”œâ”€â”€ å­¦è¡“è«–æ–‡.xml                # Genreåˆ¥Q&Aãƒ•ã‚¡ã‚¤ãƒ«XMLå½¢å¼ï¼‰
â”‚   â”œâ”€â”€ æŠ€è¡“ãƒ–ãƒ­ã‚°.xml
â”‚   â””â”€â”€ ...
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ raw.md                      # LLMã®ç”Ÿãƒ¬ã‚¹ãƒãƒ³ã‚¹
â”œâ”€â”€ dataset_alpaca.json             # ğŸ¦™ Alpacaå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ--export-alpacaã‚ªãƒ—ã‚·ãƒ§ãƒ³ä½¿ç”¨æ™‚ï¼‰
â””â”€â”€ README.md                       # ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ï¼ˆ--export-alpacaã‚ªãƒ—ã‚·ãƒ§ãƒ³ä½¿ç”¨æ™‚ï¼‰
```

## ğŸ¤– ã‚µãƒãƒ¼ãƒˆã™ã‚‹LLMãƒ¢ãƒ‡ãƒ«

### ğŸ”‘ OpenAIï¼ˆç›´æ¥ï¼‰
```bash
export OPENAI_API_KEY="sk-..."
easy-dataset generate document.txt -g ga.md -m gpt-4o
```

### ğŸŒ OpenRouterçµŒç”±
```bash
export OPENROUTER_API_KEY="sk-or-v1-..."
easy-dataset generate document.txt -g ga.md -m gpt-4o  # è‡ªå‹•ã§openai/gpt-4oã«å¤‰æ›
easy-dataset generate document.txt -g ga.md -m claude-3-sonnet  # è‡ªå‹•ã§anthropic/claude-3-sonnetã«å¤‰æ›
```

## ğŸ¤— Hugging Face Hubçµ±åˆ

### ğŸ”‘ ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

```bash
# Windows (cmd)
set HUGGINGFACE_TOKEN=hf_your_token_here

# Windows (PowerShell)
$env:HUGGINGFACE_TOKEN="hf_your_token_here"

# Linux/macOS
export HUGGINGFACE_TOKEN="hf_your_token_here"
```

### ğŸ“¤ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```bash
# ç”Ÿæˆã¨åŒæ™‚ã«Hugging Face Hubã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uv run easy-dataset generate document.txt \
  --ga-file ga.xml \
  --export-alpaca \
  --upload-hf \
  --hf-repo-name username/my-dataset

# æ—¢å­˜XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uv run easy-dataset convert-to-alpaca ./qa_directory \
  --upload-hf \
  --hf-repo-name username/my-dataset \
  --hf-private  # ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒªãƒã‚¸ãƒˆãƒªã¨ã—ã¦ä½œæˆ
```

### ğŸ“¥ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®ä½¿ç”¨æ–¹æ³•

```python
from datasets import load_dataset

# Hugging Face Hubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’èª­ã¿è¾¼ã¿
dataset = load_dataset("username/my-dataset")

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å†…å®¹ã‚’ç¢ºèª
print(dataset['train'][0])
# {
#   'instruction': 'Pythonã®è¨­è¨ˆå“²å­¦ã«ãŠã‘ã‚‹ä¸»è¦ãªç‰¹å¾´ã¯ä½•ã§ã™ã‹ï¼Ÿ',
#   'input': '',
#   'output': 'Pythonã®è¨­è¨ˆå“²å­¦ã¯ã€Œèª­ã¿ã‚„ã™ã•ã€ã‚’é‡è¦–ã—ã¦ãŠã‚Š...',
#   'genre': 'å­¦è¡“è«–æ–‡',
#   'audience': 'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ç ”ç©¶è€…'
# }

# ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿æº–å‚™
def format_instruction(example):
    return f"### æŒ‡ç¤º:\n{example['instruction']}\n\n### å›ç­”:\n{example['output']}"

formatted_dataset = dataset.map(lambda x: {"text": format_instruction(x)})
```

### ğŸ“Š è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã®ä¾‹

ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã«è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹README.mdã«ã¯ä»¥ä¸‹ã®æƒ…å ±ãŒå«ã¾ã‚Œã¾ã™ï¼š

```yaml
---
license: mit
task_categories:
- question-answering
- text-generation
language:
- ja
tags:
- alpaca
- qa
- japanese
size_categories:
- n<1K  # ãƒ‡ãƒ¼ã‚¿é‡ã«å¿œã˜ã¦è‡ªå‹•è¨­å®š
---
```

- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¦‚è¦**: ã‚¨ãƒ³ãƒˆãƒªæ•°ã€å½¢å¼ã€è¨€èªã€ãƒ©ã‚¤ã‚»ãƒ³ã‚¹
- **ã‚¸ãƒ£ãƒ³ãƒ«ãƒ»å¯¾è±¡èª­è€…åˆ†å¸ƒ**: å«ã¾ã‚Œã‚‹ã™ã¹ã¦ã®ã‚«ãƒ†ã‚´ãƒª
- **ä½¿ç”¨æ–¹æ³•**: Hugging Face Datasetsã§ã®èª­ã¿è¾¼ã¿ä¾‹
- **ç”Ÿæˆãƒ„ãƒ¼ãƒ«æƒ…å ±**: easy-dataset-cliã¸ã®ãƒªãƒ³ã‚¯

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ”— å‚è€ƒæƒ…å ±

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ä»¥ä¸‹ã®OSSã¨è«–æ–‡ã‚’å‚è€ƒã«é–‹ç™ºã•ã‚Œã¦ã„ã¾ã™ï¼š

### ğŸ“¦ å‚è€ƒOSS
- **[Easy Dataset](https://github.com/ConardLi/easy-dataset)**

### ğŸ“„ å‚è€ƒè«–æ–‡
- **[Dataset Generation for Instruction Tuning](https://arxiv.org/html/2507.04009v1)**


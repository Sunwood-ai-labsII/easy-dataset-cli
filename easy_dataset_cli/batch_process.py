#!/usr/bin/env python3
"""
ãƒãƒƒãƒå‡¦ç†æ©Ÿèƒ½
"""

from pathlib import Path
from rich.console import Console
from rich.progress import Progress

from .core import (
    parse_ga_file,
    split_text,
    get_chunk_with_surrounding_context,
    create_augmented_chunks,
    convert_to_xml_by_genre,
    create_output_directories
)
from .ga_parser import parse_ga_definitions_from_xml_improved

# generatorsãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .generators import (
    generate_qa_for_chunk_with_ga,
    generate_qa_for_chunk_with_ga_and_fulltext,
    generate_qa_for_chunk_with_ga_and_thinking,
    generate_qa_for_chunk_with_surrounding_context,
    generate_ga_definitions
)

console = Console()


def _batch_create_ga_files(text_files, output_dir, model, num_ga_pairs, max_context_length=8000):
    """è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰GAãƒšã‚¢ã‚’ãƒãƒƒãƒç”Ÿæˆã™ã‚‹å†…éƒ¨é–¢æ•°ï¼ˆå„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼‰"""

    from .core import create_output_directories, save_ga_definitions_by_genre, parse_ga_definitions_from_xml

    total_files = len(text_files)
    successful_files = []

    with Progress(console=console) as progress:
        main_task = progress.add_task("[green]GAãƒšã‚¢ã‚’ç”Ÿæˆä¸­...", total=total_files)

        for file_idx, text_file in enumerate(text_files):
            console.print(f"\n[bold cyan]å‡¦ç†ä¸­: {text_file.name}[/bold cyan]")

            try:
                # å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å°‚ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
                file_output_dir = output_dir / text_file.stem
                dirs = create_output_directories(file_output_dir)
                console.print(f"[dim]âœ“ ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: {file_output_dir}[/dim]")

                text = text_file.read_text(encoding="utf-8")
                console.print(f"[dim]âœ“ ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text):,} æ–‡å­—[/dim]")

                with console.status(f"[bold green]ğŸ¤– LLMã«GAãƒšã‚¢ã®ææ¡ˆã‚’ä¾é ¼ä¸­... ({text_file.name})[/bold green]"):
                    xml_content = generate_ga_definitions(text, model=model, num_ga_pairs=num_ga_pairs, max_context_length=max_context_length)

                # LLMã®rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’logsãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
                raw_file_path = dirs["logs"] / "raw.md"
                raw_file_path.write_text(xml_content, encoding="utf-8")
                console.print(f"[green]âœ“[/green] LLMã®rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜: [cyan]{raw_file_path.name}[/cyan]")

                with console.status(f"[bold green]ğŸ” XMLã‹ã‚‰GAãƒšã‚¢ã‚’è§£æä¸­... ({text_file.name})[/bold green]"):
                    # XMLã‹ã‚‰GAãƒšã‚¢ã‚’è§£æï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                    ga_pairs = parse_ga_definitions_from_xml_improved(xml_content)

                if not ga_pairs:
                    console.print(f"[yellow]è­¦å‘Š: {text_file.name} ã‹ã‚‰ã¯æœ‰åŠ¹ãªGAãƒšã‚¢ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ[/yellow]")
                    continue

                # å…ƒã®XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’gaãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ãªXMLã®ã¿ï¼‰
                xml_file_path = dirs["ga"] / "ga_definitions.xml"
                xml_start = xml_content.find("<GADefinitions>")
                xml_end = xml_content.rfind("</GADefinitions>")
                if xml_start != -1 and xml_end != -1:
                    clean_xml = xml_content[xml_start: xml_end + len("</GADefinitions>")]
                    xml_file_path.write_text(clean_xml, encoding="utf-8")
                    console.print(f"[green]âœ“[/green] GAå®šç¾©XMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: [cyan]{xml_file_path}[/cyan]")

                # Genreã”ã¨ã«ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’gaãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
                save_ga_definitions_by_genre(ga_pairs, dirs["ga"])

                successful_files.append((text_file.name, file_output_dir, len(ga_pairs)))
                console.print(f"[green]âœ“[/green] {len(ga_pairs)}å€‹ã®GAãƒšã‚¢ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

            except Exception as e:
                console.print(f"[red]ã‚¨ãƒ©ãƒ¼: {text_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}[/red]")
                continue

            progress.update(
                main_task, advance=1,
                description=f"å®Œäº†: {text_file.name}"
            )

    if not successful_files:
        print_error_panel("æœ‰åŠ¹ãªGAãƒšã‚¢ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\nç”Ÿæˆã•ã‚ŒãŸXMLã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        raise typer.Exit(code=1)

    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¾ã—ãè¡¨ç¤º
    total_ga_pairs = sum(count for _, _, count in successful_files)
    details = [
        f"{total_ga_pairs}å€‹ã®GAãƒšã‚¢ã‚’ç”Ÿæˆ",
        f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(successful_files)}/{total_files}å€‹",
        f"å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å°‚ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"
    ]

    # å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
    from rich.table import Table
    files_table = Table(show_header=True, box=None)
    files_table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="cyan")
    files_table.add_column("ãƒ•ã‚©ãƒ«ãƒ€", style="white")
    files_table.add_column("GAãƒšã‚¢æ•°", style="green")

    for file_name, output_path, ga_count in successful_files:
        files_table.add_row(file_name, str(output_path), str(ga_count))

    console.print(Table(title="[bold green]ğŸ“„ å‡¦ç†çµæœ[/bold green]", box=True))
    console.print(files_table)

    from .commands import print_success_summary
    print_success_summary("ãƒãƒƒãƒGAãƒšã‚¢ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼", details)

    from .commands import Panel
    next_steps_panel = Panel(
        "ğŸ” ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¬ãƒ“ãƒ¥ãƒ¼\n"
        "âœï¸ å¿…è¦ã«å¿œã˜ã¦ç·¨é›†\n"
        "ğŸš€ `generate` ã‚³ãƒãƒ³ãƒ‰ã§Q&Aç”Ÿæˆã¸",
        title="[bold yellow]ğŸ”„ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—[/bold yellow]",
        border_style="yellow"
    )
    console.print(next_steps_panel)


def _batch_process_files(text_files, ga_file, ga_base_dir, output_dir, model, chunk_size, chunk_overlap,
                        num_qa_pairs, use_fulltext, use_thinking, use_surrounding_context,
                        context_before, context_after, append_mode,
                        export_alpaca, upload_hf, hf_repo_name, hf_token, hf_private):
    """è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒãƒå‡¦ç†ã™ã‚‹å†…éƒ¨é–¢æ•°ï¼ˆå„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼‰"""

    # GAãƒšã‚¢ã®è§£æã¯å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è¡Œã†ï¼ˆga_base_dirãƒ¢ãƒ¼ãƒ‰ã®å ´åˆï¼‰
    ga_pairs = None
    if ga_file:
        with console.status("ğŸ” GAãƒšã‚¢ã‚’è§£æä¸­..."):
            ga_pairs = parse_ga_file(ga_file)

        if not ga_pairs:
            print_error_panel("æœ‰åŠ¹ãªGAãƒšã‚¢ãŒå®šç¾©ãƒ•ã‚¡ã‚¤ãƒ«ã«è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            raise typer.Exit(code=1)

        console.print(f"\n[green]âœ“[/green] {len(ga_pairs)}å€‹ã®GAãƒšã‚¢ã‚’ç™ºè¦‹ã—ã¾ã—ãŸ")

    # ãƒ¢ãƒ¼ãƒ‰è­¦å‘Šã‚’è¡¨ç¤º
    warnings = []
    if use_fulltext:
        warnings.append("ğŸ“‹ å…¨æ–‡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
    if use_thinking:
        warnings.append("ğŸ¤” æ€è€ƒãƒ•ãƒ­ãƒ¼ãƒ¢ãƒ¼ãƒ‰")
    if use_surrounding_context:
        warnings.append(f"ğŸ”— å‘¨è¾ºãƒãƒ£ãƒ³ã‚¯ãƒ¢ãƒ¼ãƒ‰ ({context_before}å‰+{context_after}å¾Œ)")

    if warnings:
        from .commands import Panel
        warning_panel = Panel(
            "\n".join(warnings) + "\n\nâš ï¸ å‡¦ç†æ™‚é–“ã¨APIã‚³ã‚¹ãƒˆãŒå¢—åŠ ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
            title="[bold yellow]âš ï¸ ãƒ¢ãƒ¼ãƒ‰è­¦å‘Š[/bold yellow]",
            border_style="yellow"
        )
        console.print(warning_panel)

    total_files = len(text_files)
    successful_files = []
    total_qa_pairs_generated = 0

    with Progress(console=console) as progress:
        main_task = progress.add_task("[green]ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...", total=total_files)

        for file_idx, text_file in enumerate(text_files):
            console.print(f"\n[bold cyan]å‡¦ç†ä¸­: {text_file.name}[/bold cyan]")

            try:
                # å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å°‚ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
                file_output_dir = output_dir / text_file.stem
                dirs = create_output_directories(file_output_dir)
                console.print(f"[dim]âœ“ ãƒ•ã‚¡ã‚¤ãƒ«ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ: {file_output_dir}[/dim]")

                text = text_file.read_text(encoding="utf-8")
                console.print(f"[dim]âœ“ ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(text):,} æ–‡å­—[/dim]")

                # GAãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ±ºå®šã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
                current_ga_path = None
                if ga_file:
                    # å¾“æ¥é€šã‚Šã€æŒ‡å®šã•ã‚ŒãŸå˜ä¸€ã®GAãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
                    current_ga_path = ga_file
                    console.print(f"[dim]âœ“ ä½¿ç”¨ã™ã‚‹GAå®šç¾©: {current_ga_path}[/dim]")
                elif ga_base_dir:
                    # å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰å¯¾å¿œã™ã‚‹GAãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’çµ„ã¿ç«‹ã¦ã‚‹
                    file_stem = text_file.stem
                    inferred_ga_path = ga_base_dir / file_stem / "ga" / "ga_definitions.xml"

                    if inferred_ga_path.exists():
                        current_ga_path = inferred_ga_path
                        console.print(f"[dim]âœ“ GAå®šç¾©ã‚’è‡ªå‹•æ¤œå‡º: {current_ga_path}[/dim]")
                    else:
                        console.print(f"[yellow]è­¦å‘Š: {text_file.name} ã«å¯¾å¿œã™ã‚‹GAå®šç¾©ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚[/yellow]")
                        console.print(f"[dim]æ¤œç´¢ãƒ‘ã‚¹: {inferred_ga_path}[/dim]")
                        continue  # æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¸

                # GAãƒšã‚¢ã‚’è§£æ
                with console.status("ğŸ” GAãƒšã‚¢ã‚’è§£æä¸­..."):
                    current_ga_pairs = parse_ga_file(current_ga_path)

                if not current_ga_pairs:
                    console.print(f"[yellow]è­¦å‘Š: {text_file.name} ã®GAå®šç¾©ã‹ã‚‰æœ‰åŠ¹ãªGAãƒšã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚[/yellow]")
                    continue

                console.print(f"[green]âœ“[/green] {len(current_ga_pairs)}å€‹ã®GAãƒšã‚¢ã‚’ç™ºè¦‹")

                with console.status(f"âœ‚ï¸ ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ä¸­... ({text_file.name})"):
                    chunks = split_text(text, chunk_size=chunk_size, chunk_overlap=chunk_overlap)
                console.print(f"[green]âœ“[/green] {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ")

                # å‘¨è¾ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ãƒãƒ£ãƒ³ã‚¯ã‚’æ‹¡å¼µ
                if use_surrounding_context:
                    with console.status(f"ğŸ”— å‘¨è¾ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆä¸­... ({text_file.name})"):
                        augmented_chunks = create_augmented_chunks(chunks, context_before, context_after)
                    console.print(f"[green]âœ“[/green] {len(augmented_chunks)}å€‹ã®æ‹¡å¼µãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆ")

                all_qa_pairs_with_ga = []
                total_tasks_for_file = len(chunks) * len(current_ga_pairs)
                file_task = progress.add_task(f"[blue]{text_file.name}", total=total_tasks_for_file)

                if use_surrounding_context:
                    # å‘¨è¾ºã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
                    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†’é ­ï¼ˆæœ€å¤§3000æ–‡å­—ï¼‰ã‚’ä»˜ä¸ã—ã¦æ–‡è„ˆã®å®‰å®šæ€§ã‚’é«˜ã‚ã‚‹
                    doc_head = text[:3000]
                    for i, (target_chunk, augmented_content, _) in enumerate(augmented_chunks):
                        for ga_pair in current_ga_pairs:
                            content_with_head = (
                                f"ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†’é ­ï¼ˆæœ€å¤§3000æ–‡å­—ï¼‰ã€‘:\n{doc_head}\n\n" +
                                augmented_content
                            )
                            qa_pairs = generate_qa_for_chunk_with_surrounding_context(
                                content=content_with_head,
                                model=model,
                                ga_pair=ga_pair,
                                logs_dir=dirs["logs"],
                                num_qa_pairs=num_qa_pairs
                            )

                            for pair in qa_pairs:
                                qa_entry = {
                                    "genre": ga_pair['genre']['title'],
                                    "audience": ga_pair['audience']['title'],
                                    "question": pair['question'],
                                    "answer": pair['answer']
                                }
                                all_qa_pairs_with_ga.append(qa_entry)

                            progress.update(
                                file_task, advance=1,
                                description=f"Genre: {ga_pair['genre']['title']}"
                            )
                else:
                    # é€šå¸¸ãƒ¢ãƒ¼ãƒ‰ã®å‡¦ç†
                    for chunk in chunks:
                        for ga_pair in current_ga_pairs:
                            if use_thinking:
                                qa_pairs = generate_qa_for_chunk_with_ga_and_thinking(
                                    chunk=chunk,
                                    full_text=text if use_fulltext else "",
                                    model=model,
                                    ga_pair=ga_pair,
                                    logs_dir=dirs["logs"],
                                    num_qa_pairs=num_qa_pairs
                                )
                            elif use_fulltext:
                                qa_pairs = generate_qa_for_chunk_with_ga_and_fulltext(
                                    chunk=chunk,
                                    full_text=text,
                                    model=model,
                                    ga_pair=ga_pair,
                                    logs_dir=dirs["logs"],
                                    num_qa_pairs=num_qa_pairs
                                )
                            else:
                                qa_pairs = generate_qa_for_chunk_with_ga(
                                    chunk, model=model, ga_pair=ga_pair,
                                    logs_dir=dirs["logs"],
                                    num_qa_pairs=num_qa_pairs
                                )

                            for pair in qa_pairs:
                                qa_entry = {
                                    "genre": ga_pair['genre']['title'],
                                    "audience": ga_pair['audience']['title'],
                                    "question": pair['question'],
                                    "answer": pair['answer']
                                }
                                all_qa_pairs_with_ga.append(qa_entry)

                            progress.update(
                                file_task, advance=1,
                                description=f"Genre: {ga_pair['genre']['title']}"
                            )

                progress.remove_task(file_task)

                # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®Q&Aãƒšã‚¢ã‚’XMLã«å¤‰æ›ã—ã¦ä¿å­˜
                xml_outputs_by_genre = convert_to_xml_by_genre(all_qa_pairs_with_ga, dirs["qa"], append_mode)

                saved_files = []
                for genre, xml_content in xml_outputs_by_genre.items():
                    from .core import sanitize_filename
                    safe_genre_name = sanitize_filename(genre)
                    output_file_path = dirs["qa"] / f"{safe_genre_name}.xml"
                    output_file_path.write_text(xml_content, encoding="utf-8")
                    saved_files.append(output_file_path.name)

                # ã‚¢ãƒ«ãƒ‘ã‚«å½¢å¼ã§ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å€‹åˆ¥ï¼‰
                if export_alpaca:
                    from .core import convert_all_xml_to_alpaca, create_dataset_card
                    alpaca_file = dirs["base"] / "dataset_alpaca.json"
                    alpaca_data = convert_all_xml_to_alpaca(dirs["qa"], alpaca_file)

                    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
                    readme_file = dirs["base"] / "README.md"
                    create_dataset_card(alpaca_data, readme_file, f"Generated QA Dataset from {text_file.name}")

                successful_files.append((text_file.name, file_output_dir, len(all_qa_pairs_with_ga), saved_files))
                total_qa_pairs_generated += len(all_qa_pairs_with_ga)
                console.print(f"[green]âœ“[/green] {len(all_qa_pairs_with_ga)}å€‹ã®Q&Aãƒšã‚¢ã‚’ç”Ÿæˆ")

            except Exception as e:
                console.print(f"[red]ã‚¨ãƒ©ãƒ¼: {text_file.name} ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}[/red]")
                continue

            progress.update(
                main_task, advance=1,
                description=f"å®Œäº†: {text_file.name}"
            )

    if not successful_files:
        from .commands import print_error_panel
        print_error_panel("æœ‰åŠ¹ãªQ&Aãƒšã‚¢ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
        import typer
        raise typer.Exit(code=1)

    # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¾ã—ãè¡¨ç¤º
    details = [
        f"{total_qa_pairs_generated}å€‹ã®Q&Aãƒšã‚¢ã‚’ç”Ÿæˆ",
        f"å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«: {len(successful_files)}/{total_files}å€‹",
        f"å„ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«å°‚ç”¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"
    ]

    # å‡¦ç†ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º
    from rich.table import Table
    files_table = Table(show_header=True, box=None)
    files_table.add_column("ãƒ•ã‚¡ã‚¤ãƒ«", style="cyan")
    files_table.add_column("ãƒ•ã‚©ãƒ«ãƒ€", style="white")
    files_table.add_column("Q&Aãƒšã‚¢æ•°", style="green")

    for file_name, output_path, qa_count, _ in successful_files:
        files_table.add_row(file_name, str(output_path), str(qa_count))

    console.print(Table(title="[bold green]ğŸ“„ å‡¦ç†çµæœ[/bold green]", box=True))
    console.print(files_table)

    from .commands import print_success_summary
    print_success_summary("ãƒãƒƒãƒQ&Aç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼", details)

    # Hugging Face Hubã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ï¼ˆæœ€åˆã®æˆåŠŸãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã€ã¾ãŸã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå€‹åˆ¥æŒ‡å®šï¼‰
    if upload_hf and export_alpaca:
        if not hf_repo_name:
            console.print("[bold red]--hf-repo-nameãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼[/bold red]")
            console.print("[yellow]ä¾‹: --hf-repo-name username/my-qa-dataset[/yellow]")
        else:
            console.print(f"\n[bold blue]Hugging Face Hub ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«ã¤ã„ã¦[/bold blue]")
            console.print("[yellow]æ³¨æ„: ç¾åœ¨ã¯å„ãƒ•ã‚¡ã‚¤ãƒ«ãŒå€‹åˆ¥ã®ãƒ•ã‚©ãƒ«ãƒ€ã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€")
            console.print("å€‹åˆ¥ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã€çµ±åˆã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã‹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚[/yellow]")


def print_error_panel(error_msg: str):
    """ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç¾ã—ãè¡¨ç¤º"""
    panel = f"[bold red]âŒ ã‚¨ãƒ©ãƒ¼[/bold red]\n{error_msg}"
    console.print(panel)

#!/usr/bin/env python3
"""
åŸºæœ¬çš„ãªQ&Aç”Ÿæˆæ©Ÿèƒ½
"""

import os
import xml.etree.ElementTree as ET
from xml.dom import minidom
from pathlib import Path
from typing import List, Dict
from openai import OpenAI
from rich.console import Console
from dotenv import load_dotenv
import traceback
import json
from datetime import datetime

from ..prompts import get_qa_generation_prompt
from ..xml_utils import parse_qa_from_text_fallback

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

console = Console()


def generate_qa_for_chunk_with_ga(
    chunk: str,
    model: str,
    ga_pair: Dict[str, Dict[str, str]],
    logs_dir: Path = None,
    num_qa_pairs: int = None
) -> List[Dict[str, str]]:
    """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½¿ã„ã€1ã¤ã®ãƒãƒ£ãƒ³ã‚¯ã¨1ã¤ã®GAãƒšã‚¢ã‹ã‚‰Q&Aãƒšã‚¢ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    prompt_template = get_qa_generation_prompt()
    prompt = prompt_template.format(
        context=chunk,
        genre_title=ga_pair['genre']['title'],
        genre_description=ga_pair['genre']['description'],
        audience_title=ga_pair['audience']['title'],
        audience_description=ga_pair['audience']['description'],
        num_qa_pairs=num_qa_pairs if num_qa_pairs is not None else "è¤‡æ•°ã®"
    )

    messages = [
        {"role": "system", "content": "ã‚ãªãŸã¯ã€XMLå½¢å¼ã§å³å¯†ã«å‡ºåŠ›ã™ã‚‹å„ªç§€ãªã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é€šå¸¸ã®XMLã®ç‰¹æ®Šæ–‡å­—ï¼ˆ&, \", 'ï¼‰ã¯é©åˆ‡ã«ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¦ãã ã•ã„ã€‚ãŸã ã—ã€<Question>ã€<Answer>ã€<think>ã‚¿ã‚°ã¯ãã®ã¾ã¾ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ”¹è¡Œã¯å«ã‚ãšã«å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"},
        {"role": "user", "content": prompt}
    ]

    # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
    client = OpenAI(
        base_url=os.getenv("OPENAI_BASE_URL", "https://openrouter.ai/api/v1"),
        api_key=os.getenv("OPENAI_API_KEY"),
    )

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ããƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    genre_safe = "".join(c for c in ga_pair['genre']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')
    audience_safe = "".join(c for c in ga_pair['audience']['title'] if c.isalnum() or c in (' ', '-', '_')).strip().replace(' ', '_')

    # ãƒªãƒˆãƒ©ã‚¤+ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
    import time, random
    max_retries = 3
    timeout_sec = int(os.getenv("EASY_DATASET_TIMEOUT", "120"))
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜
        if logs_dir:
            request_log = {
                "timestamp": timestamp,
                "model": model,
                "genre": ga_pair['genre']['title'],
                "audience": ga_pair['audience']['title'],
                "prompt_length": len(prompt),
                "messages": messages
            }
            request_filename = f"request_{genre_safe}_{audience_safe}_{timestamp}.json"
            request_file_path = logs_dir / request_filename
            with open(request_file_path, 'w', encoding='utf-8') as f:
                json.dump(request_log, f, ensure_ascii=False, indent=2)
            console.print(f"[dim]ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°ã‚’ä¿å­˜: {request_filename}[/dim]")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            prompt_filename = f"prompt_{genre_safe}_{audience_safe}_{timestamp}.md"
            prompt_file_path = logs_dir / prompt_filename
            prompt_content = f"""# QAç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

**ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:** {timestamp}  
**ãƒ¢ãƒ‡ãƒ«:** {model}  
**ã‚¸ãƒ£ãƒ³ãƒ«:** {ga_pair['genre']['title']}  
**ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹:** {ga_pair['audience']['title']}  
**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•·:** {len(prompt)} æ–‡å­—

---

## ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

{messages[0]['content']}

---

## ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ

{prompt}
"""
            prompt_file_path.write_text(prompt_content, encoding='utf-8')
            console.print(f"[dim]ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: {prompt_filename}[/dim]")

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡æ™‚åˆ»ã‚’è¨˜éŒ²
        request_start = datetime.now()
        
        # é€ä¿¡ï¼ˆãƒªãƒˆãƒ©ã‚¤ï¼‰
        response = None
        last_err = None
        for attempt in range(1, max_retries + 1):
            try:
                response = client.chat.completions.create(
                    model=model,
                    messages=messages,
                    timeout=timeout_sec
                )
                break
            except Exception as e:
                last_err = e
                wait_s = min(2 ** attempt + random.random(), 10)
                console.print(f"[yellow]APIãƒªãƒˆãƒ©ã‚¤ {attempt}/{max_retries} å¤±æ•—: {e}[/yellow]")
                if attempt < max_retries:
                    console.print(f"[dim]{wait_s:.1f}s å¾…æ©Ÿå¾Œã«å†è©¦è¡Œ[/dim]")
                    time.sleep(wait_s)
        if response is None:
            raise last_err
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡æ™‚åˆ»ã‚’è¨˜éŒ²
        request_end = datetime.now()
        processing_time = (request_end - request_start).total_seconds()
        
        xml_content = response.choices[0].message.content

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜ï¼ˆè©³ç´°æƒ…å ±ä»˜ãï¼‰
        if logs_dir:
            response_log = {
                "metadata": {
                    "timestamp": timestamp,
                    "request_start": request_start.isoformat(),
                    "request_end": request_end.isoformat(),
                    "processing_time_seconds": processing_time,
                    "model": model
                },
                "generation_context": {
                    "genre": {
                        "title": ga_pair['genre']['title'],
                        "description": ga_pair['genre']['description'][:100] + "..." if len(ga_pair['genre']['description']) > 100 else ga_pair['genre']['description']
                    },
                    "audience": {
                        "title": ga_pair['audience']['title'],
                        "description": ga_pair['audience']['description'][:100] + "..." if len(ga_pair['audience']['description']) > 100 else ga_pair['audience']['description']
                    },
                    "chunk_length": len(chunk),
                    "prompt_length": len(prompt)
                },
                "api_response": {
                    "response_length": len(xml_content),
                    "response_content": xml_content
                }
            }
            response_filename = f"response_{genre_safe}_{audience_safe}_{timestamp}.json"
            response_file_path = logs_dir / response_filename
            with open(response_file_path, 'w', encoding='utf-8') as f:
                json.dump(response_log, f, ensure_ascii=False, indent=2)
            console.print(f"[dim]ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°ã‚’ä¿å­˜: {response_filename} (å‡¦ç†æ™‚é–“: {processing_time:.2f}s)[/dim]")

        # rawãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ä¿å­˜ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if logs_dir:
            raw_filename = f"qa_raw_{genre_safe}_{audience_safe}_{timestamp}.md"
            raw_file_path = logs_dir / raw_filename
            raw_file_path.write_text(xml_content, encoding="utf-8")

        qa_pairs = _parse_qa_response(xml_content, logs_dir, genre_safe, audience_safe, timestamp)

        # ç”Ÿæˆã—ãŸQAã‚’ä¿å­˜
        if qa_pairs and logs_dir:
            qa_filename = f"qa_pairs_{genre_safe}_{audience_safe}_{timestamp}.xml"
            _save_qa_pairs_to_xml(qa_pairs, logs_dir, qa_filename)

        # å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
        if logs_dir:
            _save_execution_summary(logs_dir, timestamp, genre_safe, audience_safe, {
                "processing_time": processing_time,
                "qa_count": len(qa_pairs),
                "success": True,
                "chunk_length": len(chunk),
                "prompt_length": len(prompt),
                "response_length": len(xml_content)
            })

        return qa_pairs

    except Exception as general_error:
        # è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º
        console.print(f"[bold red]ãƒãƒ£ãƒ³ã‚¯ã¨GAãƒšã‚¢ã‹ã‚‰ã®Q&Aç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:[/bold red]")
        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:[/bold red] {type(general_error).__name__}")
        console.print(f"[bold red]ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:[/bold red] {str(general_error)}")
        console.print(f"[bold red]ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:[/bold red]")
        console.print(traceback.format_exc())
        console.print(f"[dim]Genre: {ga_pair['genre']['title']}, Audience: {ga_pair['audience']['title']}[/dim]")

        # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
        if logs_dir:
            error_log = {
                "timestamp": timestamp,
                "model": model,
                "genre": ga_pair['genre']['title'],
                "audience": ga_pair['audience']['title'],
                "error_type": type(general_error).__name__,
                "error_message": str(general_error),
                "traceback": traceback.format_exc()
            }
            error_filename = f"error_{genre_safe}_{audience_safe}_{timestamp}.json"
            error_file_path = logs_dir / error_filename
            with open(error_file_path, 'w', encoding='utf-8') as f:
                json.dump(error_log, f, ensure_ascii=False, indent=2)
            console.print(f"[dim]ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜: {error_filename}[/dim]")

        # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜
        if logs_dir:
            _save_execution_summary(logs_dir, timestamp, genre_safe, audience_safe, {
                "processing_time": 0,
                "qa_count": 0,
                "success": False,
                "error_type": type(general_error).__name__,
                "error_message": str(general_error),
                "chunk_length": len(chunk) if chunk else 0,
                "prompt_length": len(prompt) if prompt else 0,
                "response_length": 0
            })

        return []


def _parse_qa_response(xml_content: str, logs_dir: Path = None, genre_safe: str = None, audience_safe: str = None, timestamp: str = None) -> List[Dict[str, str]]:
    """Q&Aç”Ÿæˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®XMLã‚’è§£æã™ã‚‹ï¼ˆå…±é€šå‡¦ç†ï¼‰"""
    qa_pairs = []

    # LLMã‹ã‚‰ã®å‡ºåŠ›ã®å‰å‡¦ç†ï¼šä¸è¦ãªãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»
    cleaned_content = _clean_llm_response(xml_content)

    # XMLéƒ¨åˆ†ã®ã¿ã‚’æŠ½å‡º - å„ªå…ˆçš„ã«<QAPairs>ã‚¿ã‚°ã‚’æ¢ã™
    xml_start = cleaned_content.find("<QAPairs>")
    xml_end = cleaned_content.rfind("</QAPairs>")

    # <QAPairs>ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯<Pair>ã‚¿ã‚°ã§æŠ½å‡ºã‚’è©¦è¡Œ
    if xml_start == -1 or xml_end == -1:
        console.print("[yellow]<QAPairs>ã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€<Pair>ã‚¿ã‚°ã§æŠ½å‡ºã‚’è©¦è¡Œã—ã¾ã™...[/yellow]")
        xml_start = cleaned_content.find("<Pair>")
        xml_end = cleaned_content.rfind("</Pair>")

        # <Pair>ã‚¿ã‚°ã§å›²ã¾ã‚ŒãŸéƒ¨åˆ†ã‚’æŠ½å‡º
        if xml_start != -1 and xml_end != -1:
            # ã™ã¹ã¦ã®<Pair>...</Pair>ã‚’æŠ½å‡º
            import re
            pair_pattern = r'<Pair>.*?</Pair>'
            pair_matches = re.findall(pair_pattern, cleaned_content, re.DOTALL)

            for pair_match in pair_matches:
                # å„Pairã‹ã‚‰Questionã¨Answerã‚’æŠ½å‡º
                question_match = re.search(r'<Question>(.*?)</Question>', pair_match, re.DOTALL)
                answer_match = re.search(r'<Answer>(.*?)</Answer>', pair_match, re.DOTALL)

                if question_match and answer_match:
                    qa_pairs.append({
                        "question": _decode_xml_entities(question_match.group(1).strip()),
                        "answer": _decode_xml_entities(answer_match.group(1).strip())
                    })

            if qa_pairs:
                console.print(f"[green]âœ“[/green] <Pair>ã‚¿ã‚°ã‹ã‚‰{len(qa_pairs)}ä»¶ã®Q&Aã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
                return qa_pairs

    if xml_start != -1 and xml_end != -1:
        clean_xml = cleaned_content[xml_start: xml_end + len("</QAPairs>")]

        # XMLè§£æç”¨ã®ãƒ­ã‚°ã‚’ä¿å­˜
        if logs_dir and genre_safe and audience_safe and timestamp:
            xml_debug_log = {
                "timestamp": timestamp,
                "original_xml_content": xml_content[:500],
                "cleaned_xml_content": cleaned_content[:500],
                "final_xml_content": clean_xml,
                "xml_length": len(clean_xml)
            }
            xml_debug_filename = f"xml_debug_{genre_safe}_{audience_safe}_{timestamp}.json"
            xml_debug_file_path = logs_dir / xml_debug_filename
            with open(xml_debug_file_path, 'w', encoding='utf-8') as f:
                json.dump(xml_debug_log, f, ensure_ascii=False, indent=2)

        try:
            root = ET.fromstring(clean_xml)

            for pair_node in root.findall('Pair'):
                question_node = pair_node.find('Question')
                answer_node = pair_node.find('Answer')

                if question_node is not None and answer_node is not None:
                    question_text = question_node.text or ""

                    # <Answer>è¦ç´ å†…ã®å†…å®¹ã‚’é©åˆ‡ã«å–å¾—
                    if len(answer_node) > 0:
                        # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒã‚ã‚‹å ´åˆï¼ˆ<think>ã‚¿ã‚°ãªã©ï¼‰
                        answer_parts = []

                        # Answerè¦ç´ ã®ç›´æ¥ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ<think>ã‚ˆã‚Šå‰ï¼‰
                        if answer_node.text:
                            answer_parts.append(answer_node.text.strip())

                        # å„ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®tailï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆï¼‰
                        for child in answer_node:
                            if child.tag == 'think':
                                # <think>ã‚¿ã‚°ã®å†…å®¹ã‚’å–å¾—
                                think_content = child.text or ""
                                answer_parts.append(f"<think>{think_content}</think>")

                            # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆ
                            if child.tail:
                                answer_parts.append(child.tail.strip())

                        answer_text = "".join(answer_parts)
                    else:
                        # ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆãŒãªã„å ´åˆã¯é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆ
                        answer_text = answer_node.text or ""

                    # XMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ãƒ‡ã‚³ãƒ¼ãƒ‰
                    question_text = _decode_xml_entities(question_text)
                    answer_text = _decode_xml_entities(answer_text)

                    qa_pairs.append({
                        "question": question_text,
                        "answer": answer_text
                    })

        except ET.ParseError as parse_error:
            # XMLãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆã€æ‰‹å‹•ã§ãƒ†ã‚­ã‚¹ãƒˆè§£æ
            console.print("[yellow]XMLãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã€è‡ªå‹•è§£æã‚’è©¦è¡Œä¸­...[/yellow]")
            console.print(f"[dim]ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(parse_error)}[/dim]")

            # ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ä¿å­˜
            if logs_dir and genre_safe and audience_safe and timestamp:
                parse_error_log = {
                    "timestamp": timestamp,
                    "error_type": "XML_ParseError",
                    "error_message": str(parse_error),
                    "xml_content": clean_xml
                }
                parse_error_filename = f"xml_parse_error_{genre_safe}_{audience_safe}_{timestamp}.json"
                parse_error_file_path = logs_dir / parse_error_filename
                with open(parse_error_file_path, 'w', encoding='utf-8') as f:
                    json.dump(parse_error_log, f, ensure_ascii=False, indent=2)

            # è‡ªå‹•è§£æã‚’è©¦è¡Œ
            qa_pairs = parse_qa_from_text_fallback(clean_xml)

            # è‡ªå‹•è§£æã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            if not qa_pairs:
                console.print("[yellow]è‡ªå‹•è§£æã‚‚å¤±æ•—ã—ãŸãŸã‚ã€ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥Q&Aã‚’æŠ½å‡ºã—ã¾ã™...[/yellow]")
                qa_pairs = _extract_qa_from_fallback_text(cleaned_content)

    if not qa_pairs:
        console.print(f"[bold red]LLMãŒç”Ÿæˆã—ãŸXMLã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ[/bold red]")
        console.print(f"[dim]å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ: {cleaned_content[:500]}...[/dim]")

        # è§£æå¤±æ•—ã®ãƒ­ã‚°ã‚’ä¿å­˜
        if logs_dir and genre_safe and audience_safe and timestamp:
            failure_log = {
                "timestamp": timestamp,
                "failure_reason": "XMLè§£æå¤±æ•—",
                "original_content": xml_content[:1000],
                "cleaned_content": cleaned_content[:1000]
            }
            failure_filename = f"xml_parse_failure_{genre_safe}_{audience_safe}_{timestamp}.json"
            failure_file_path = logs_dir / failure_filename
            with open(failure_file_path, 'w', encoding='utf-8') as f:
                json.dump(failure_log, f, ensure_ascii=False, indent=2)

    return qa_pairs


def _clean_llm_response(response: str) -> str:
    """LLMã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹"""
    import re

    # ä¸è¦ãªãƒ†ã‚­ã‚¹ãƒˆã‚’é™¤å»
    cleaned = response

    # ```xml ... ``` ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    cleaned = re.sub(r'```xml\s*|\s*```', '', cleaned, flags=re.IGNORECASE)

    # ``` ... ``` ã®ã‚ˆã†ãªã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    cleaned = re.sub(r'```\s*|\s*```', '', cleaned)

    # <xml> ... </xml> ã®ã‚ˆã†ãªã‚¿ã‚°ã‚’é™¤å»
    cleaned = re.sub(r'<xml>\s*|\s*</xml>', '', cleaned, flags=re.IGNORECASE)

    # ä¸è¦ãªç©ºç™½ã‚„æ”¹è¡Œã‚’æ•´ç†
    cleaned = re.sub(r'\s+', ' ', cleaned).strip()

    return cleaned


def _extract_qa_from_fallback_text(text: str) -> List[Dict[str, str]]:
    """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥Q&Aã‚’æŠ½å‡ºã™ã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°"""
    qa_pairs = []

    try:
        # <Question>ã¨<Answer>ã‚¿ã‚°ã§åˆ†å‰²
        import re

        # Questionã‚¿ã‚°ã‚’æ¤œç´¢
        question_pattern = r'<Question>(.*?)</Question>'
        answer_pattern = r'<Answer>(.*?)</Answer>'

        questions = re.findall(question_pattern, text, re.DOTALL)
        answers = re.findall(answer_pattern, text, re.DOTALL)

        # åŒã˜æ•°ã®è³ªå•ã¨å›ç­”ãŒã‚ã‚‹å ´åˆã®ã¿ãƒšã‚¢ã‚’ä½œæˆ
        min_count = min(len(questions), len(answers))
        for i in range(min_count):
            qa_pairs.append({
                "question": _decode_xml_entities(questions[i].strip()),
                "answer": _decode_xml_entities(answers[i].strip())
            })

    except Exception as e:
        console.print(f"[red]ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£æã‚‚å¤±æ•—:[/red] {e}")

    return qa_pairs


def _decode_xml_entities(text: str) -> str:
    """XMLã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
    import html
    if text:
        return html.unescape(text)
    return text


def _save_qa_pairs_to_xml(qa_pairs: List[Dict[str, str]], logs_dir: Path, qa_filename: str) -> None:
    """Q&Aãƒšã‚¢ã‚’ãã‚Œã„ã«æ•´å½¢ã•ã‚ŒãŸXMLãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ï¼ˆã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆæ–¹å¼ï¼‰"""
    if not qa_pairs or not logs_dir:
        return

    qa_file_path = logs_dir / qa_filename

    # ElementTreeã§æ§‹é€ åŒ–ç”Ÿæˆ
    root = ET.Element("QAPairs")
    for qa in qa_pairs:
        pair_elem = ET.SubElement(root, "Pair")
        question_elem = ET.SubElement(pair_elem, "Question")
        question_elem.text = qa["question"]

        answer_elem = ET.SubElement(pair_elem, "Answer")

        # å›ç­”å†…å®¹ã‚’è§£æ
        parsed_answer = _parse_answer_with_think(qa["answer"])

        if parsed_answer["has_think"]:
            # <think>ã‚’ã‚µãƒ–ã‚¨ãƒ¬ãƒ¡ãƒ³ãƒˆã¨ã—ã¦è¿½åŠ 
            think_elem = ET.SubElement(answer_elem, "think")
            think_elem.text = parsed_answer["think_content"]
            think_elem.tail = parsed_answer["answer_content"]
        else:
            # é€šå¸¸ã®å›ç­”
            answer_elem.text = parsed_answer["answer_content"]

    # æ•´å½¢ã—ã¦ä¿å­˜
    rough_string = ET.tostring(root, 'utf-8')
    reparsed = minidom.parseString(rough_string)
    pretty_xml = reparsed.toprettyxml(indent="  ")

    qa_file_path.write_text(pretty_xml, encoding='utf-8')
    console.print(f"[green]âœ“[/green] QAãƒšã‚¢ã‚’ä¿å­˜: {qa_filename} ({len(qa_pairs)}ä»¶)")


def _parse_answer_with_think(answer_text: str) -> Dict[str, str]:
    """<think>ã‚¿ã‚°ã‚’å«ã‚€å›ç­”ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦åˆ†é›¢"""
    import re

    # <think>...</think>ã‚¿ã‚°ã‚’æ¤œç´¢
    think_match = re.search(r'<think>(.*?)</think>', answer_text, re.DOTALL)

    if think_match:
        think_content = think_match.group(1).strip()
        # <think>ã‚¿ã‚°ä»¥é™ã®å›ç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—
        answer_content = answer_text[think_match.end():].strip()
        return {
            "has_think": True,
            "think_content": think_content,
            "answer_content": answer_content
        }
    else:
        return {
            "has_think": False,
            "think_content": "",
            "answer_content": answer_text
        }


def _save_execution_summary(logs_dir: Path, timestamp: str, genre_safe: str, audience_safe: str, summary_data: Dict) -> None:
    """å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã¨JSONã§ä¿å­˜"""
    if not logs_dir:
        return
    
    # JSONã‚µãƒãƒªãƒ¼
    json_summary = {
        "timestamp": timestamp,
        "genre": genre_safe,
        "audience": audience_safe,
        "execution_summary": summary_data
    }
    
    json_filename = f"summary_{genre_safe}_{audience_safe}_{timestamp}.json"
    json_file_path = logs_dir / json_filename
    with open(json_file_path, 'w', encoding='utf-8') as f:
        json.dump(json_summary, f, ensure_ascii=False, indent=2)
    
    # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚µãƒãƒªãƒ¼
    md_filename = f"summary_{genre_safe}_{audience_safe}_{timestamp}.md"
    md_file_path = logs_dir / md_filename
    
    status_emoji = "âœ…" if summary_data.get("success", False) else "âŒ"
    
    md_content = f"""# QAç”Ÿæˆå®Ÿè¡Œã‚µãƒãƒªãƒ¼ {status_emoji}

**ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—:** {timestamp}  
**ã‚¸ãƒ£ãƒ³ãƒ«:** {genre_safe.replace('_', ' ')}  
**ã‚ªãƒ¼ãƒ‡ã‚£ã‚¨ãƒ³ã‚¹:** {audience_safe.replace('_', ' ')}  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹:** {'æˆåŠŸ' if summary_data.get('success', False) else 'å¤±æ•—'}

## ğŸ“Š å®Ÿè¡Œçµ±è¨ˆ

| é …ç›® | å€¤ |
|------|-----|
| å‡¦ç†æ™‚é–“ | {summary_data.get('processing_time', 0):.2f}ç§’ |
| ç”Ÿæˆã•ã‚ŒãŸQAæ•° | {summary_data.get('qa_count', 0)}ä»¶ |
| ãƒãƒ£ãƒ³ã‚¯é•· | {summary_data.get('chunk_length', 0):,}æ–‡å­— |
| ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé•· | {summary_data.get('prompt_length', 0):,}æ–‡å­— |
| ãƒ¬ã‚¹ãƒãƒ³ã‚¹é•· | {summary_data.get('response_length', 0):,}æ–‡å­— |

## ğŸ“ é–¢é€£ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«

- `prompt_{genre_safe}_{audience_safe}_{timestamp}.md` - ä½¿ç”¨ã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
- `request_{genre_safe}_{audience_safe}_{timestamp}.json` - ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ­ã‚°  
- `response_{genre_safe}_{audience_safe}_{timestamp}.json` - ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ­ã‚°
- `qa_raw_{genre_safe}_{audience_safe}_{timestamp}.md` - ç”ŸRAWãƒ¬ã‚¹ãƒãƒ³ã‚¹
"""

    if summary_data.get("success", False):
        md_content += f"- `qa_pairs_{genre_safe}_{audience_safe}_{timestamp}.xml` - ç”Ÿæˆã•ã‚ŒãŸQAãƒšã‚¢\n"
    else:
        md_content += f"""
## âŒ ã‚¨ãƒ©ãƒ¼è©³ç´°

**ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—:** {summary_data.get('error_type', 'Unknown')}  
**ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:** {summary_data.get('error_message', 'No message')}

- `error_{genre_safe}_{audience_safe}_{timestamp}.json` - ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°
"""
    
    md_file_path.write_text(md_content, encoding='utf-8')
    console.print(f"[dim]å®Ÿè¡Œã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {md_filename}[/dim]")
